{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ДЗ4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxEA3zsT46YqbCvQMmUaPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/map72ru/matalg/blob/main/%D0%94%D0%974.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msrGDWUcbPWU"
      },
      "source": [
        "1. В коде из методички реализуйте один или несколько из критериев останова (количество листьев, количество используемых признаков, глубина дерева и т.д.).\n",
        "\n",
        "Добавлен класс Conditions и реализованы остановки по глубине дерева, количеству объектов в листе (как параметр), количеству листов, в так же по уровню ошибки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk7eHKGZyvGT"
      },
      "source": [
        "import math\n",
        "\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Реализуем класс узла\n",
        "\n",
        "class Node:\n",
        "\n",
        "    def __init__(self, index, t, true_branch, false_branch):\n",
        "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
        "        self.t = t  # значение порога\n",
        "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
        "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n",
        "\n",
        "\n",
        "# И класс терминального узла (листа)\n",
        "\n",
        "class Leaf:\n",
        "\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.prediction = self.predict()\n",
        "\n",
        "    def predict(self):\n",
        "        # подсчет количества объектов разных классов\n",
        "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
        "        for label in self.labels:\n",
        "            if label not in classes:\n",
        "                classes[label] = 0\n",
        "            classes[label] += 1\n",
        "        #  найдем класс, количество объектов которого будет максимальным в этом листе и вернем его\n",
        "        prediction = max(classes, key=classes.get)\n",
        "        return prediction\n",
        "\n",
        "class Conditions:\n",
        "    max_levels = -1\n",
        "    max_leafs = -1\n",
        "    min_quality = -1\n",
        "    min_objects = 5\n",
        "\n",
        "    __cur_leafs = 0\n",
        "    __cur_levels = 0\n",
        "\n",
        "    def inc_leaf(self):\n",
        "        self.__cur_leafs += 1\n",
        "\n",
        "    def apply(self):\n",
        "        if self.max_levels > -1 and self.__cur_levels >= self.max_levels:\n",
        "            return True\n",
        "\n",
        "        if self.max_leafs > -1 and self.__cur_leafs >= self.max_leafs:\n",
        "            return True\n",
        "\n",
        "        self.__cur_levels += 1\n",
        "        return False\n",
        "\n",
        "    def check_quality(self, current_quality):\n",
        "        return self.min_quality > -1 and current_quality <= self.min_quality\n",
        "\n",
        "# Расчет критерия Джини\n",
        "\n",
        "def gini(labels):\n",
        "    #  подсчет количества объектов разных классов\n",
        "    classes = {}\n",
        "    for label in labels:\n",
        "        if label not in classes:\n",
        "            classes[label] = 0\n",
        "        classes[label] += 1\n",
        "\n",
        "    #  расчет критерия\n",
        "    impurity = 1\n",
        "    for label in classes:\n",
        "        p = classes[label] / len(labels)\n",
        "        impurity -= p ** 2\n",
        "\n",
        "    return impurity\n",
        "\n",
        "def entropy(labels):\n",
        "    classes = {}\n",
        "    for label in labels:\n",
        "        if label not in classes:\n",
        "            classes[label] = 0\n",
        "        classes[label] += 1\n",
        "\n",
        "    #  расчет критерия\n",
        "    entropy = 0\n",
        "    for label in classes:\n",
        "        p = classes[label] / len(labels)\n",
        "        entropy += p * math.log(p, 2)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "# Расчет качества\n",
        "\n",
        "def quality(left_labels, right_labels, current_crit, criteria):\n",
        "    # доля выбоки, ушедшая в левое поддерево\n",
        "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
        "\n",
        "    return current_crit - p * criteria(left_labels) - (1 - p) * criteria(right_labels)\n",
        "\n",
        "# Разбиение датасета в узле\n",
        "\n",
        "def split(data, labels, index, t):\n",
        "    left = np.where(data[:, index] <= t)\n",
        "    right = np.where(data[:, index] > t)\n",
        "\n",
        "    true_data = data[left]\n",
        "    false_data = data[right]\n",
        "    true_labels = labels[left]\n",
        "    false_labels = labels[right]\n",
        "\n",
        "    return true_data, false_data, true_labels, false_labels\n",
        "\n",
        "# Нахождение наилучшего разбиения\n",
        "\n",
        "def find_best_split(data, labels, conditions, criteria):\n",
        "    #  обозначим минимальное количество объектов в узле\n",
        "    if conditions is not None:\n",
        "        min_leaf = conditions.min_objects\n",
        "    else:\n",
        "        min_leaf = 5\n",
        "\n",
        "    current_crit = criteria(labels)\n",
        "\n",
        "    best_quality = 0\n",
        "    best_t = None\n",
        "    best_index = None\n",
        "\n",
        "    n_features = data.shape[1]\n",
        "\n",
        "    for index in range(n_features):\n",
        "        # будем проверять только уникальные значения признака, исключая повторения\n",
        "        t_values = np.unique([row[index] for row in data])\n",
        "\n",
        "        for t in t_values:\n",
        "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
        "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
        "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
        "                continue\n",
        "\n",
        "            current_quality = quality(true_labels, false_labels, current_crit, criteria)\n",
        "\n",
        "            #  выбираем порог, на котором получается максимальный прирост качества\n",
        "            if current_quality > best_quality:\n",
        "                best_quality, best_t, best_index = current_quality, t, index\n",
        "\n",
        "    return best_quality, best_t, best_index\n",
        "\n",
        "# Построение дерева с помощью рекурсивной функции\n",
        "\n",
        "def build_tree(data, labels, conditions = None, criteria = gini):\n",
        "\n",
        "    # Ограничения по дереву\n",
        "    if conditions is not None:\n",
        "        if conditions.apply():\n",
        "            return Leaf(data, labels)\n",
        "\n",
        "    quality, t, index = find_best_split(data, labels, conditions, criteria)\n",
        "\n",
        "    if conditions is not None:\n",
        "        if conditions.check_quality(quality):\n",
        "            conditions.inc_leaf()\n",
        "            return Leaf(data, labels)\n",
        "\n",
        "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
        "    if quality == 0:\n",
        "        if conditions is not None:\n",
        "            conditions.inc_leaf()\n",
        "        return Leaf(data, labels)\n",
        "\n",
        "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
        "\n",
        "    # Рекурсивно строим два поддерева\n",
        "    true_branch = build_tree(true_data, true_labels, conditions)\n",
        "    false_branch = build_tree(false_data, false_labels, conditions)\n",
        "\n",
        "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
        "    return Node(index, t, true_branch, false_branch)\n",
        "\n",
        "def classify_object(obj, node):\n",
        "\n",
        "    #  Останавливаем рекурсию, если достигли листа\n",
        "    if isinstance(node, Leaf):\n",
        "        answer = node.prediction\n",
        "        return answer\n",
        "\n",
        "    if obj[node.index] <= node.t:\n",
        "        return classify_object(obj, node.true_branch)\n",
        "    else:\n",
        "        return classify_object(obj, node.false_branch)\n",
        "\n",
        "\n",
        "def predict(data, tree):\n",
        "    classes = []\n",
        "    for obj in data:\n",
        "        prediction = classify_object(obj, tree)\n",
        "        classes.append(prediction)\n",
        "    return classes\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4oqYGgBvoe0"
      },
      "source": [
        "# Разобьем выборку на обучающую и тестовую\n",
        "\n",
        "from sklearn import model_selection\n",
        "\n",
        "# сгенерируем данные\n",
        "classification_data, classification_labels = datasets.make_classification(n_samples=1000, n_features = 3, n_informative = 3,\n",
        "                                                      n_classes = 3, n_redundant=0,\n",
        "                                                      n_clusters_per_class=1, random_state=5)\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(classification_data,\n",
        "                                                                                     classification_labels,\n",
        "                                                                                     test_size = 0.3,\n",
        "                                                                                     random_state = 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0sDqkq1v3MO"
      },
      "source": [
        "Просто проверим, что все работает"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbs40b3_vyHt",
        "outputId": "7575d115-edbc-4765-8c5e-1a33458de6b3"
      },
      "source": [
        "# Построим дерево по обучающей выборке\n",
        "my_tree = build_tree(train_data, train_labels)\n",
        "\n",
        "# Напечатаем ход нашего дерева\n",
        "def print_tree(node, spacing=\"\"):\n",
        "    # Если лист, то выводим его прогноз\n",
        "    if isinstance(node, Leaf):\n",
        "        print(spacing + \"Прогноз:\", node.prediction)\n",
        "        return\n",
        "\n",
        "    # Выведем значение индекса и порога на этом узле\n",
        "    print(spacing + 'Индекс', str(node.index))\n",
        "    print(spacing + 'Порог', str(node.t))\n",
        "\n",
        "    # Рекурсионный вызов функции на положительном поддереве\n",
        "    print(spacing + '--> True:')\n",
        "    print_tree(node.true_branch, spacing + \"  \")\n",
        "\n",
        "    # Рекурсионный вызов функции на положительном поддереве\n",
        "    print(spacing + '--> False:')\n",
        "    print_tree(node.false_branch, spacing + \"  \")\n",
        "\n",
        "\n",
        "print_tree(my_tree)\n",
        "\n",
        "# Получим ответы для обучающей выборки\n",
        "train_answers = predict(train_data, my_tree)\n",
        "\n",
        "# И получим ответы для тестовой выборки\n",
        "answers = predict(test_data, my_tree)\n",
        "\n",
        "# Введем функцию подсчета точности как доли правильных ответов\n",
        "def accuracy_metric(actual, predicted):\n",
        "    correct = 0\n",
        "    for i in range(len(actual)):\n",
        "        if actual[i] == predicted[i]:\n",
        "            correct += 1\n",
        "    return correct / float(len(actual)) * 100.0\n",
        "\n",
        "# Точность на обучающей выборке\n",
        "train_accuracy = accuracy_metric(train_labels, train_answers)\n",
        "print('train_accuracy',train_accuracy)\n",
        "\n",
        "# Точность на тестовой выборке\n",
        "test_accuracy = accuracy_metric(test_labels, answers)\n",
        "print('test_accuracy', test_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Индекс 1\n",
            "Порог 0.291136309339993\n",
            "--> True:\n",
            "  Индекс 0\n",
            "  Порог -0.7094546141261373\n",
            "  --> True:\n",
            "    Индекс 2\n",
            "    Порог -4.03544097413468\n",
            "    --> True:\n",
            "      Прогноз: 1\n",
            "    --> False:\n",
            "      Прогноз: 1\n",
            "  --> False:\n",
            "    Индекс 1\n",
            "    Порог -0.16234689302965566\n",
            "    --> True:\n",
            "      Индекс 0\n",
            "      Порог -0.21733916492530092\n",
            "      --> True:\n",
            "        Прогноз: 2\n",
            "      --> False:\n",
            "        Индекс 2\n",
            "        Порог -3.163219683887811\n",
            "        --> True:\n",
            "          Прогноз: 2\n",
            "        --> False:\n",
            "          Индекс 0\n",
            "          Порог 3.059135223077212\n",
            "          --> True:\n",
            "            Прогноз: 2\n",
            "          --> False:\n",
            "            Прогноз: 2\n",
            "    --> False:\n",
            "      Индекс 0\n",
            "      Порог 2.0029661862505383\n",
            "      --> True:\n",
            "        Индекс 0\n",
            "        Порог -0.056964246499989324\n",
            "        --> True:\n",
            "          Индекс 2\n",
            "          Порог -1.7714876459826936\n",
            "          --> True:\n",
            "            Прогноз: 2\n",
            "          --> False:\n",
            "            Прогноз: 1\n",
            "        --> False:\n",
            "          Индекс 1\n",
            "          Порог 0.07344292828091659\n",
            "          --> True:\n",
            "            Прогноз: 2\n",
            "          --> False:\n",
            "            Индекс 2\n",
            "            Порог -0.919973809205186\n",
            "            --> True:\n",
            "              Прогноз: 2\n",
            "            --> False:\n",
            "              Индекс 0\n",
            "              Порог 0.5735418675973536\n",
            "              --> True:\n",
            "                Прогноз: 1\n",
            "              --> False:\n",
            "                Прогноз: 2\n",
            "      --> False:\n",
            "        Прогноз: 0\n",
            "--> False:\n",
            "  Индекс 0\n",
            "  Порог 0.14399218146622084\n",
            "  --> True:\n",
            "    Индекс 2\n",
            "    Порог 1.3240159612040112\n",
            "    --> True:\n",
            "      Индекс 2\n",
            "      Порог -1.2118161472039928\n",
            "      --> True:\n",
            "        Индекс 0\n",
            "        Порог -0.9721687055654452\n",
            "        --> True:\n",
            "          Индекс 0\n",
            "          Порог -1.522019482057825\n",
            "          --> True:\n",
            "            Прогноз: 1\n",
            "          --> False:\n",
            "            Индекс 2\n",
            "            Порог -2.0252819240171664\n",
            "            --> True:\n",
            "              Прогноз: 2\n",
            "            --> False:\n",
            "              Прогноз: 1\n",
            "        --> False:\n",
            "          Индекс 2\n",
            "          Порог -1.434006484076393\n",
            "          --> True:\n",
            "            Прогноз: 2\n",
            "          --> False:\n",
            "            Прогноз: 2\n",
            "      --> False:\n",
            "        Индекс 0\n",
            "        Порог -0.03442511656622671\n",
            "        --> True:\n",
            "          Индекс 2\n",
            "          Порог -0.9903837639247853\n",
            "          --> True:\n",
            "            Индекс 0\n",
            "            Порог -0.9591203155910639\n",
            "            --> True:\n",
            "              Прогноз: 1\n",
            "            --> False:\n",
            "              Прогноз: 1\n",
            "          --> False:\n",
            "            Прогноз: 1\n",
            "        --> False:\n",
            "          Индекс 1\n",
            "          Порог 1.3959282563107691\n",
            "          --> True:\n",
            "            Прогноз: 2\n",
            "          --> False:\n",
            "            Прогноз: 1\n",
            "    --> False:\n",
            "      Индекс 1\n",
            "      Порог 2.0846171424470143\n",
            "      --> True:\n",
            "        Индекс 0\n",
            "        Порог -0.6299050754717019\n",
            "        --> True:\n",
            "          Прогноз: 0\n",
            "        --> False:\n",
            "          Прогноз: 0\n",
            "      --> False:\n",
            "        Прогноз: 1\n",
            "  --> False:\n",
            "    Индекс 1\n",
            "    Порог 1.5939000670457455\n",
            "    --> True:\n",
            "      Индекс 2\n",
            "      Порог -0.015059882215687881\n",
            "      --> True:\n",
            "        Прогноз: 2\n",
            "      --> False:\n",
            "        Индекс 0\n",
            "        Порог 0.7865818372139093\n",
            "        --> True:\n",
            "          Индекс 2\n",
            "          Порог 0.8235169826980406\n",
            "          --> True:\n",
            "            Прогноз: 1\n",
            "          --> False:\n",
            "            Индекс 1\n",
            "            Порог 0.8429744066577386\n",
            "            --> True:\n",
            "              Прогноз: 0\n",
            "            --> False:\n",
            "              Индекс 2\n",
            "              Порог 1.124668226882306\n",
            "              --> True:\n",
            "                Прогноз: 0\n",
            "              --> False:\n",
            "                Прогноз: 0\n",
            "        --> False:\n",
            "          Индекс 2\n",
            "          Порог 1.140095365415611\n",
            "          --> True:\n",
            "            Прогноз: 0\n",
            "          --> False:\n",
            "            Прогноз: 0\n",
            "    --> False:\n",
            "      Индекс 0\n",
            "      Порог 0.6304065400897707\n",
            "      --> True:\n",
            "        Прогноз: 1\n",
            "      --> False:\n",
            "        Прогноз: 1\n",
            "train_accuracy 96.14285714285714\n",
            "test_accuracy 94.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ4kvA5Axnrj"
      },
      "source": [
        "Введем ограничения по глубине дерева"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTeSO7y0xbg3",
        "outputId": "03ed0ebe-5f64-4a17-d2c4-dd3dfef10046"
      },
      "source": [
        "\n",
        "#\n",
        "# Построим дерево с ограничениями\n",
        "\n",
        "conditions = Conditions()\n",
        "conditions.max_levels = 3\n",
        "# Построим дерево по обучающей выборке\n",
        "my_tree = build_tree(train_data, train_labels, conditions)\n",
        "\n",
        "print_tree(my_tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Индекс 1\n",
            "Порог 0.291136309339993\n",
            "--> True:\n",
            "  Индекс 0\n",
            "  Порог -0.7094546141261373\n",
            "  --> True:\n",
            "    Индекс 2\n",
            "    Порог -4.03544097413468\n",
            "    --> True:\n",
            "      Прогноз: 1\n",
            "    --> False:\n",
            "      Прогноз: 1\n",
            "  --> False:\n",
            "    Прогноз: 2\n",
            "--> False:\n",
            "  Прогноз: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGZgCghk04mt"
      },
      "source": [
        "2. Для задачи классификации обучить дерево решений с использованием критериев разбиения Джини и Энтропия. Сравнить качество классификации, сделать выводы.\n",
        "\n",
        "Посчитаем с критерием по энтропии Шеннона и сравним с первым результатом"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC24mphQyIL9",
        "outputId": "32151cea-1123-479f-f607-69afb177b69e"
      },
      "source": [
        "# Построим дерево по обучающей выборке\n",
        "my_tree = build_tree(train_data, train_labels, criteria=entropy)\n",
        "\n",
        "# Получим ответы для обучающей выборки\n",
        "entropy_train_answers = predict(train_data, my_tree)\n",
        "\n",
        "# И получим ответы для тестовой выборки\n",
        "answers = predict(test_data, my_tree)\n",
        "\n",
        "# Точность на обучающей выборке\n",
        "entropy_train_accuracy = accuracy_metric(train_labels, entropy_train_answers)\n",
        "print('entropy_train_accuracy',entropy_train_accuracy)\n",
        "\n",
        "# Точность на тестовой выборке\n",
        "entropy_test_accuracy = accuracy_metric(test_labels, answers)\n",
        "print('entropy_test_accuracy', entropy_test_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entropy_train_accuracy 33.85714285714286\n",
            "entropy_test_accuracy 31.666666666666664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSwhEmhXz2dN"
      },
      "source": [
        "На данной выборке (1000 измерений, 3 признака) критерий энтропии Шеннона дает результат значительно хуже, чем критерий Джини. Пробовал увеличивать/уменьшать размер выборки и кол-во признаков, отношение значений двух критериев кардинально не менялось. Скорее всего причина в самой сути данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s8J7qcz5cyV"
      },
      "source": [
        "3 [опция]. Реализуйте дерево для задачи регрессии. Возьмите за основу дерево, реализованное в методичке, заменив механизм предсказания в листе на взятие среднего значения по выборке, и критерий Джини на дисперсию значений."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSJG7k1v5l8T"
      },
      "source": [
        "import math\n",
        "\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Реализуем класс узла\n",
        "\n",
        "class Node:\n",
        "\n",
        "    def __init__(self, index, t, true_branch, false_branch):\n",
        "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
        "        self.t = t  # значение порога\n",
        "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
        "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n",
        "\n",
        "\n",
        "# И класс терминального узла (листа)\n",
        "\n",
        "class Leaf:\n",
        "\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.prediction = self.predict()\n",
        "\n",
        "    def predict(self):\n",
        "        return np.mean(self.labels)\n",
        "\n",
        "class Conditions:\n",
        "    max_levels = -1\n",
        "    max_leafs = -1\n",
        "    min_quality = -1\n",
        "    min_objects = 5\n",
        "\n",
        "    __cur_leafs = 0\n",
        "    __cur_levels = 0\n",
        "\n",
        "    def inc_leaf(self):\n",
        "        self.__cur_leafs += 1\n",
        "\n",
        "    def apply(self):\n",
        "        if self.max_levels > -1 and self.__cur_levels >= self.max_levels:\n",
        "            return True\n",
        "\n",
        "        if self.max_leafs > -1 and self.__cur_leafs >= self.max_leafs:\n",
        "            return True\n",
        "\n",
        "        self.__cur_levels += 1\n",
        "        return False\n",
        "\n",
        "    def check_quality(self, current_quality):\n",
        "        return self.min_quality > -1 and current_quality <= self.min_quality\n",
        "\n",
        "# Расчет критерия Джини\n",
        "\n",
        "def gini(labels):\n",
        "    #  подсчет количества объектов разных классов\n",
        "    classes = {}\n",
        "    for label in labels:\n",
        "        if label not in classes:\n",
        "            classes[label] = 0\n",
        "        classes[label] += 1\n",
        "\n",
        "    #  расчет критерия\n",
        "    impurity = 1\n",
        "    for label in classes:\n",
        "        p = classes[label] / len(labels)\n",
        "        impurity -= p ** 2\n",
        "\n",
        "    return impurity\n",
        "\n",
        "def variance(labels):\n",
        "    mean = np.mean(labels)\n",
        "    return np.sum((labels-mean)**2)/len(labels)\n",
        "\n",
        "def entropy(labels):\n",
        "    classes = {}\n",
        "    for label in labels:\n",
        "        if label not in classes:\n",
        "            classes[label] = 0\n",
        "        classes[label] += 1\n",
        "\n",
        "    #  расчет критерия\n",
        "    entropy = 0\n",
        "    for label in classes:\n",
        "        p = classes[label] / len(labels)\n",
        "        entropy += p * math.log(p, 2)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "# Расчет качества\n",
        "\n",
        "def quality(left_labels, right_labels, current_crit, criteria):\n",
        "    # доля выбоки, ушедшая в левое поддерево\n",
        "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
        "\n",
        "    return current_crit - p * criteria(left_labels) - (1 - p) * criteria(right_labels)\n",
        "\n",
        "# Разбиение датасета в узле\n",
        "\n",
        "def split(data, labels, index, t):\n",
        "    left = np.where(data[:, index] <= t)\n",
        "    right = np.where(data[:, index] > t)\n",
        "\n",
        "    true_data = data[left]\n",
        "    false_data = data[right]\n",
        "    true_labels = labels[left]\n",
        "    false_labels = labels[right]\n",
        "\n",
        "    return true_data, false_data, true_labels, false_labels\n",
        "\n",
        "# Нахождение наилучшего разбиения\n",
        "\n",
        "def find_best_split(data, labels, conditions, criteria):\n",
        "    #  обозначим минимальное количество объектов в узле\n",
        "    if conditions is not None:\n",
        "        min_leaf = conditions.min_objects\n",
        "    else:\n",
        "        min_leaf = 5\n",
        "\n",
        "    current_crit = criteria(labels)\n",
        "\n",
        "    best_quality = 0\n",
        "    best_t = None\n",
        "    best_index = None\n",
        "\n",
        "    n_features = data.shape[1]\n",
        "\n",
        "    for index in range(n_features):\n",
        "        # будем проверять только уникальные значения признака, исключая повторения\n",
        "        t_values = np.unique([row[index] for row in data])\n",
        "\n",
        "        for t in t_values:\n",
        "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
        "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
        "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
        "                continue\n",
        "\n",
        "            current_quality = quality(true_labels, false_labels, current_crit, criteria)\n",
        "\n",
        "            #  выбираем порог, на котором получается максимальный прирост качества\n",
        "            if current_quality > best_quality:\n",
        "                best_quality, best_t, best_index = current_quality, t, index\n",
        "\n",
        "    return best_quality, best_t, best_index\n",
        "\n",
        "# Построение дерева с помощью рекурсивной функции\n",
        "\n",
        "def build_tree(data, labels, conditions = None, criteria = gini):\n",
        "\n",
        "    # Ограничения по дереву\n",
        "    if conditions is not None:\n",
        "        if conditions.apply():\n",
        "            return Leaf(data, labels)\n",
        "\n",
        "    quality, t, index = find_best_split(data, labels, conditions, criteria)\n",
        "\n",
        "    if conditions is not None:\n",
        "        if conditions.check_quality(quality):\n",
        "            conditions.inc_leaf()\n",
        "            return Leaf(data, labels)\n",
        "\n",
        "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
        "    if quality == 0:\n",
        "        if conditions is not None:\n",
        "            conditions.inc_leaf()\n",
        "        return Leaf(data, labels)\n",
        "\n",
        "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
        "\n",
        "    # Рекурсивно строим два поддерева\n",
        "    true_branch = build_tree(true_data, true_labels, conditions)\n",
        "    false_branch = build_tree(false_data, false_labels, conditions)\n",
        "\n",
        "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
        "    return Node(index, t, true_branch, false_branch)\n",
        "\n",
        "def classify_object(obj, node):\n",
        "\n",
        "    #  Останавливаем рекурсию, если достигли листа\n",
        "    if isinstance(node, Leaf):\n",
        "        answer = node.prediction\n",
        "        return answer\n",
        "\n",
        "    if obj[node.index] <= node.t:\n",
        "        return classify_object(obj, node.true_branch)\n",
        "    else:\n",
        "        return classify_object(obj, node.false_branch)\n",
        "\n",
        "\n",
        "def predict(data, tree):\n",
        "    classes = []\n",
        "    for obj in data:\n",
        "        prediction = classify_object(obj, tree)\n",
        "        classes.append(prediction)\n",
        "    return classes\n",
        "\n",
        "# Разобьем выборку на обучающую и тестовую"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IRTQwpP7aKK"
      },
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "# сгенерируем данные\n",
        "classification_data, classification_labels = datasets.make_regression(n_samples=1000, n_features = 3, n_informative = 3,\n",
        "                                                                      noise=0.1)\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(classification_data,\n",
        "                                                                                     classification_labels,\n",
        "                                                                                     test_size = 0.3,\n",
        "                                                                                     random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H3dmBF372Xe"
      },
      "source": [
        "tree = build_tree(train_data, train_labels, criteria=variance)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KUflUB_87iG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d31e461-2042-4413-85d1-e391cb8c2595"
      },
      "source": [
        "# В качестве метрики возьмем коэффициент детерминации\n",
        "def determination(y, y_predict):\n",
        "  return 1-np.sum((y-y_predict)**2)/np.sum((y-np.mean(y))**2)\n",
        "\n",
        "\n",
        "# Получим ответы для обучающей выборки\n",
        "var_train_answers = predict(train_data, tree)\n",
        "\n",
        "# И получим ответы для тестовой выборки\n",
        "var_answers = predict(test_data, tree)\n",
        "\n",
        "# Точность на обучающей выборке\n",
        "var_train_accuracy = determination(train_labels, var_train_answers)\n",
        "print('var_train_accuracy',var_train_accuracy)\n",
        "\n",
        "# Точность на тестовой выборке\n",
        "var_test_accuracy = determination(test_labels, var_answers)\n",
        "print('var_test_accuracy', var_test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "var_train_accuracy 0.7279230632634396\n",
            "var_test_accuracy 0.6413070032850283\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}